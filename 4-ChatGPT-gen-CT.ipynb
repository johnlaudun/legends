{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea5697f9-66d3-478e-933c-023b8971cd42",
   "metadata": {},
   "source": [
    "# GenCT\n",
    "\n",
    "This notebook combines various blocks of code from the previous notebooks to allow a user to grab the top hot posts, here 200, from `r/conspiracy`; get the topics; and then feed a random selection of topics and a random post as a model to ChatGPT to derive a new post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf6c41e-e578-42d1-b469-60dfb821dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os, praw, pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.tokenize import word_tokenize\n",
    "import openai, random\n",
    "\n",
    "# SECRET DECODER RING\n",
    "webber_id = os.getenv(\"REDDIT_API_ID\")\n",
    "webber_secret = os.getenv(\"REDDIT_API_SECRET\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ddf7e06",
   "metadata": {},
   "source": [
    "## Get Posts from Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc459e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=webber_id,\n",
    "    client_secret=webber_secret,\n",
    "    user_agent=\"webber\"\n",
    "    )\n",
    "print(reddit.read_only)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30dc9e41-eef5-47bc-9374-541b7902f063",
   "metadata": {},
   "source": [
    "This block could be streamlined to capture only `post.selftext` and to hand that list off to the subsequent blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7edbccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conspiracy = reddit.subreddit('conspiracy')\n",
    "\n",
    "posts = []\n",
    "for post in conspiracy.hot(limit=200):\n",
    "    posts.append(post.selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71e3cab-958f-40ba-923a-244658d0f8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Right now on this sub you have a top post of Biden’s son massive Sex Scandal trending at number 3 on this sub right now. \\n\\nhttps://www.reddit.com/r/conspiracy/comments/13zj3ve/beaver_hunter_bidens_laptop_pics_are_hilarious/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=2&utm_term=1\\n\\nThe fact that this ISNT trending on Big Tech or Reddit tells you how fucking biased Big Tech is. This is the President’s SON. The media went crazy over Golden Shower tapes that never existed. \\n\\nYet here you have content gold that would sell bigly in the press and yet because of Partisan Politics silence.. \\n\\nTrump, Clinton, Anthony Weiner, the list goes on.\\n\\nType in Trump Golden Shower on Google and you get:\\n\\n8,420,000 results (0.47 seconds)\\n\\nType in Hunter Biden Sex on Google and you get:\\n\\n7,910,000 results (0.57 seconds)\\n\\nOne thing doesn’t exist (Golden Shower) the other thing does. \\n\\nThe Hunter Biden Sex Scandal has so much content for the media to sell it’s crazy and yet because it’s there team it’s (D) ifferent. The Hunter Biden Sex Scandal would destroy any candidate. This is Joe Biden raised his son. That’s why it matters. How can you be tough on crime when you allow your own son to get away with Prostitution, Gun violations, tax fraud, and drug crime. \\n\\nEverything that he claimed to be against when Joe wrote that crime bill when he was a Senator for 50 years. He allows his Son to get away with.',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc7fc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130143"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(posts)\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b29a3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonan = [x for x in posts if str(x) != 'nan']\n",
    "substantive = [post for post in nonan if len(post) > 299]\n",
    "len(substantive)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc897b14-978f-4563-aa1e-d9901c806986",
   "metadata": {},
   "source": [
    "## Get Topics from Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065efb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Functions\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "def topic_details(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"{:d}: \".format(topic_idx)\n",
    "        message += \" \".join([feature_names[i] + ' ' + str(round(topic[i], 2)) + ','\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "def just_words(model, feature_names, n_top_words):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        words = \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        topics.append(words)\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9914e96-85f3-4998-87a5-3268ec2162da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1276,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETTINGS\n",
    "n_topics = 20\n",
    "n_features = 5000\n",
    "n_top_words = 5\n",
    "n_top_documents = 5\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "vectorizer = TfidfVectorizer(max_df = 0.9, \n",
    "                             min_df = 2, \n",
    "                             max_features = n_features,\n",
    "                             stop_words = 'english',\n",
    "                                  )\n",
    "X = vectorizer.fit_transform(substantive)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a60823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jl/miniconda3/envs/DEV/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 500 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# the NMF topic model\n",
    "model = NMF(n_components=n_topics, \n",
    "            init='random',\n",
    "            random_state=0, \n",
    "            max_iter=500\n",
    ")\n",
    "W = model.fit_transform(X)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae1e0dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: yah 1.27, hermes 0.94, called 0.92, light 0.87, ai 0.72,\n",
      "1: night 0.54, saw 0.5, started 0.48, bit 0.46, getting 0.36,\n",
      "2: youtube 1.17, watch 1.08, www 0.87, https 0.84, com 0.83,\n",
      "3: believe 1.92, flat 1.03, earth 0.86, hold 0.64, wealth 0.58,\n",
      "4: kids 0.98, federal 0.64, children 0.5, elite 0.45, body 0.39,\n",
      "5: thought 2.76, just 1.88, data 1.1, ve 1.0, ai 0.91,\n",
      "6: accounts 1.99, gold 1.55, basically 1.47, typically 1.26, match 1.23,\n",
      "7: crop 1.26, evidence 1.15, circles 0.83, burst 0.83, inside 0.61,\n",
      "8: study 1.42, working 0.8, https 0.78, twitter 0.59, status 0.55,\n",
      "9: apart 0.94, giant 0.77, information 0.75, service 0.62, censored 0.61,\n",
      "10: goverment 1.43, gain 0.97, money 0.66, election 0.58, fund 0.55,\n",
      "11: military 2.13, ukraine 1.28, spending 1.01, know 0.95, defense 0.92,\n",
      "12: days 1.32, x200b 1.22, june 0.98, day 0.85, 27 0.57,\n",
      "13: epstein 1.36, parties 0.68, white 0.67, people 0.46, office 0.42,\n",
      "14: dna 1.08, sun 0.83, consciousness 0.83, carbon 0.78, humanity 0.76,\n",
      "15: world 1.31, humans 0.95, new 0.77, internet 0.71, soon 0.61,\n",
      "16: https 0.98, biden 0.94, hunter 0.88, www 0.85, com 0.82,\n",
      "17: obviously 1.23, guy 0.85, exact 0.77, like 0.54, source 0.53,\n",
      "18: reddit 2.23, people 0.64, banned 0.63, dots 0.6, money 0.57,\n",
      "19: god 0.61, identity 0.45, really 0.44, uk 0.38, british 0.32,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_details(model, features, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d444a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yah hermes called light ai plasma said zeus bound mercury\n",
      "night saw started bit getting weird hands like dots raised\n",
      "youtube watch www https com png associated hundreds wiped specifically\n",
      "believe flat earth hold wealth media thoughts culture think controlled\n",
      "kids federal children elite body wants dragon columbia expression kid\n",
      "thought just data ve ai totally qanon explains best topic\n",
      "accounts gold basically typically match unless wanted couple post day\n",
      "crop evidence circles burst inside proof plant real youtu maybe\n",
      "study working https twitter status 20 mental com long scientific\n",
      "apart giant information service censored search sources interesting pushed video\n",
      "goverment gain money election fund ive care dollars elites person\n",
      "military ukraine spending know defense nato actually russia big oil\n",
      "days x200b june day 27 july taiwan year china 223\n",
      "epstein parties white people office bit father mention founding like\n",
      "dna sun consciousness carbon humanity rna earth entities history ascension\n",
      "world humans new internet soon technology enter digital created realm\n",
      "https biden hunter www com 2019 son html 07 19\n",
      "obviously guy exact like source video way disagrees storage chemical\n",
      "reddit people banned dots money threat censored successful censorship speaks\n",
      "god identity really uk british cia crisis like going doing\n"
     ]
    }
   ],
   "source": [
    "topics = just_words(model, features, 10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ff11f2-c897-46b8-9285-82035867251f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keyword_clusters = [word_tokenize(topic) for topic in topics]\n",
    "keywords =  [word for sublist in keyword_clusters for word in sublist]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c2a625a-0686-4016-b5d1-8ad6105d6af2",
   "metadata": {},
   "source": [
    "## BYOCT: Build Your Own Conspiracy Theory with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3f812fa-6575-40f2-8d94-350399632885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use these instructions for all queries\n",
    "instructions = \"\"\"\n",
    "\"You are an assistant designed to create texts.\n",
    "\"\"\"\n",
    "\n",
    "def chatgptquery (query):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        temperature = 1.0,\n",
    "        top_p = 0.5,\n",
    "        messages=[{\"role\": \"assistant\", \"content\": instructions},\n",
    "                  {\"role\": \"user\", \"content\": query}])\n",
    "    tokens = completion.usage.total_tokens\n",
    "    reply_content = completion.choices[0].message.content\n",
    "    # Get the seed, token usage, and the text\n",
    "    print(tokens)\n",
    "    print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26becbe3-88ec-46d1-b93f-c09aa8a96638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n",
      "Reddit is everywhere, it's on your phone, on your computer, in your conversations, in your thoughts. They say that they do not know if it is harmful or not, but it obviously is, it's not natural. Do they actually know what Reddit does and only pretend not to know? Are we being brainwashed? I heard that Reddit can act as a breeding ground for extremist ideologies, for example. It seems sinister to me. Also, it seems convenient to the entities that control Reddit to keep the idea that Reddit is harmless. These entities also control the media. Maybe it's somehow connected? Brainwashing the masses and then controlling the narrative? Not sure, possibly a loose connection. But one thing is for sure, Reddit is here to stay and we need to be cautious of its influence on our day-to-day lives.\n",
      "['reddit', 'entities', 'day']\n"
     ]
    }
   ],
   "source": [
    "# Keys are our words from the topic model\n",
    "keys = random.sample(keywords, 3)\n",
    "# Model is one of the posts\n",
    "model = random.sample(substantive,1)\n",
    "\n",
    "query = f\"\"\"\n",
    "Create a text in the style of the text provided below\n",
    "but change the topics to: {keys}.\n",
    "\n",
    "{model}\n",
    "\"\"\"\n",
    "\n",
    "chatgptquery(query)\n",
    "print(keys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
