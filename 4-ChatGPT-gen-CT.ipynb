{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea5697f9-66d3-478e-933c-023b8971cd42",
   "metadata": {},
   "source": [
    "# GenCT\n",
    "\n",
    "This notebook combines various blocks of code from the previous notebooks to allow a user to grab the top hot posts, here 200, from `r/conspiracy`; get the topics; and then feed a random selection of topics and a random post as a model to ChatGPT to derive a new post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf6c41e-e578-42d1-b469-60dfb821dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os, praw, pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.tokenize import word_tokenize\n",
    "import openai, random\n",
    "\n",
    "# SECRET DECODER RING\n",
    "webber_id = os.getenv(\"REDDIT_API_ID\")\n",
    "webber_secret = os.getenv(\"REDDIT_API_SECRET\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ddf7e06",
   "metadata": {},
   "source": [
    "## Get Posts from Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc459e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=webber_id,\n",
    "    client_secret=webber_secret,\n",
    "    user_agent=\"webber\"\n",
    "    )\n",
    "print(reddit.read_only)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30dc9e41-eef5-47bc-9374-541b7902f063",
   "metadata": {},
   "source": [
    "This block could be streamlined to capture only `post.selftext` and to hand that list off to the subsequent blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7edbccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conspiracy = reddit.subreddit('conspiracy')\n",
    "\n",
    "data = []\n",
    "for post in conspiracy.hot(limit=200):\n",
    "    data.append([post.title, \n",
    "                  post.score, \n",
    "                  post.id, \n",
    "                  post.url, \n",
    "                  post.num_comments, \n",
    "                  post.selftext, \n",
    "                  post.created])\n",
    "\n",
    "df = pd.DataFrame(data,\n",
    "                     columns=['title', 'score', 'id', 'url', 'num_comments', 'post', 'created'])\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71e3cab-958f-40ba-923a-244658d0f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"rc-posts-3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cc7fc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157600"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = df.post.tolist()\n",
    "text = ' '.join(posts)\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonan = [x for x in posts if str(x) != 'nan']\n",
    "substantive = [post for post in nonan if len(post) > 299]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc897b14-978f-4563-aa1e-d9901c806986",
   "metadata": {},
   "source": [
    "## Get Topics from Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "065efb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Functions\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "def topic_details(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"{:d}: \".format(topic_idx)\n",
    "        message += \" \".join([feature_names[i] + ' ' + str(round(topic[i], 2)) + ','\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "def just_words(model, feature_names, n_top_words):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        words = \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        topics.append(words)\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9914e96-85f3-4998-87a5-3268ec2162da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1480,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETTINGS\n",
    "n_topics = 20\n",
    "n_features = 5000\n",
    "n_top_words = 10\n",
    "n_top_documents = 5\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "vectorizer = TfidfVectorizer(max_df = 0.9, \n",
    "                             min_df = 2, \n",
    "                             max_features = n_features,\n",
    "                             stop_words = 'english',\n",
    "                                  )\n",
    "X = vectorizer.fit_transform(substantive)\n",
    "features = vectorizer.get_feature_names_out()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a60823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the NMF topic model\n",
    "model = NMF(n_components=n_topics, \n",
    "            init='random',\n",
    "            random_state=0, \n",
    "            max_iter=500\n",
    ")\n",
    "W = model.fit_transform(X)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae1e0dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: nature 0.38, god 0.33, world 0.31, people 0.19, make 0.18, like 0.18, consciousness 0.17, order 0.16, energy 0.16, question 0.15,\n",
      "1: ones 0.28, really 0.26, different 0.19, chatgpt 0.18, wonder 0.16, share 0.15, facebook 0.13, repeatedly 0.12, results 0.12, starts 0.12,\n",
      "2: joe 0.51, military 0.37, event 0.25, legal 0.22, epstein 0.22, picture 0.2, political 0.19, think 0.16, imagine 0.15, campaign 0.15,\n",
      "3: x200b 1.72, days 1.02, 22 0.75, 11 0.66, august 0.59, year 0.57, 23 0.54, 223 0.49, later 0.47, 28 0.46,\n",
      "4: crop 0.93, evidence 0.9, circles 0.64, burst 0.57, proof 0.43, inside 0.41, plant 0.4, real 0.33, youtu 0.31, video 0.3,\n",
      "5: flat 1.44, earthers 1.02, earth 0.86, 5g 0.8, start 0.68, group 0.67, ll 0.65, media 0.35, believe 0.27, interested 0.26,\n",
      "6: mossad 1.01, israel 0.77, agents 0.74, service 0.74, agent 0.7, secret 0.68, epstein 0.6, killed 0.46, died 0.45, conclusion 0.29,\n",
      "7: america 1.03, effort 0.98, department 0.77, conditions 0.73, abuse 0.71, child 0.7, track 0.69, report 0.69, brothers 0.66, mention 0.64,\n",
      "8: just 2.13, thought 1.18, ai 0.95, think 0.73, job 0.72, data 0.7, dont 0.68, way 0.67, 2024 0.65, good 0.63,\n",
      "9: people 2.16, time 1.91, went 1.11, slowly 1.04, says 0.92, don 0.48, maybe 0.35, close 0.29, caught 0.27, bit 0.25,\n",
      "10: post 2.65, reddit 2.33, posts 1.19, 100 1.01, despite 0.89, hours 0.89, freedom 0.82, right 0.81, accounts 0.78, attempts 0.73,\n",
      "11: https 0.93, png 0.66, 17 0.55, webp 0.54, redd 0.54, format 0.54, width 0.54, auto 0.54, preview 0.54, enabled 0.52,\n",
      "12: uk 2.55, bbc 1.55, news 1.13, www 0.93, world 0.93, material 0.85, mr 0.78, government 0.7, covid 0.59, https 0.58,\n",
      "13: ve 2.31, wondering 1.19, just 1.12, evil 1.01, place 0.89, shit 0.68, win 0.6, gone 0.58, accept 0.57, certain 0.57,\n",
      "14: theory 1.58, conspiracy 1.2, favourite 1.1, claim 0.55, argue 0.53, hidden 0.53, claims 0.48, user 0.45, control 0.44, devices 0.44,\n",
      "15: https 1.97, com 1.36, www 1.16, youtube 0.65, science 0.48, trust 0.47, 11 0.44, chinese 0.34, election 0.28, watch 0.28,\n",
      "16: falling 1.9, weather 1.51, like 1.48, michael 1.4, famous 1.4, support 1.16, animals 0.85, absorbing 0.51, causing 0.5, unusual 0.5,\n",
      "17: brazil 1.4, looking 0.85, india 0.85, accept 0.82, russia 0.81, members 0.76, south 0.75, new 0.69, china 0.68, doc 0.68,\n",
      "18: believe 2.98, leave 1.08, matter 1.05, link 1.04, wondering 1.02, article 0.94, read 0.92, controlled 0.66, culture 0.65, china 0.61,\n",
      "19: story 1.46, information 1.38, apart 1.29, sure 1.16, spanish 1.03, hard 1.03, ago 0.97, censored 0.95, event 0.93, died 0.88,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_details(model, features, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d444a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nature god world people make like consciousness order energy question\n",
      "ones really different chatgpt wonder share facebook repeatedly results starts\n",
      "joe military event legal epstein picture political think imagine campaign\n",
      "x200b days 22 11 august year 23 223 later 28\n",
      "crop evidence circles burst proof inside plant real youtu video\n",
      "flat earthers earth 5g start group ll media believe interested\n",
      "mossad israel agents service agent secret epstein killed died conclusion\n",
      "america effort department conditions abuse child track report brothers mention\n",
      "just thought ai think job data dont way 2024 good\n",
      "people time went slowly says don maybe close caught bit\n",
      "post reddit posts 100 despite hours freedom right accounts attempts\n",
      "https png 17 webp redd format width auto preview enabled\n",
      "uk bbc news www world material mr government covid https\n",
      "ve wondering just evil place shit win gone accept certain\n",
      "theory conspiracy favourite claim argue hidden claims user control devices\n",
      "https com www youtube science trust 11 chinese election watch\n",
      "falling weather like michael famous support animals absorbing causing unusual\n",
      "brazil looking india accept russia members south new china doc\n",
      "believe leave matter link wondering article read controlled culture china\n",
      "story information apart sure spanish hard ago censored event died\n"
     ]
    }
   ],
   "source": [
    "topics = just_words(model, features, 10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03ff11f2-c897-46b8-9285-82035867251f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keyword_clusters = [word_tokenize(topic) for topic in topics]\n",
    "keywords =  [word for sublist in keyword_clusters for word in sublist]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c2a625a-0686-4016-b5d1-8ad6105d6af2",
   "metadata": {},
   "source": [
    "## BYOCT: Build Your Own Conspiracy Theory with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3f812fa-6575-40f2-8d94-350399632885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use these instructions for all queries\n",
    "instructions = \"\"\"\n",
    "\"You are an assistant designed to create texts.\n",
    "\"\"\"\n",
    "\n",
    "def chatgptquery (query):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        temperature = 1.0,\n",
    "        top_p = 0.5,\n",
    "        messages=[{\"role\": \"assistant\", \"content\": instructions},\n",
    "                  {\"role\": \"user\", \"content\": query}])\n",
    "    tokens = completion.usage.total_tokens\n",
    "    reply_content = completion.choices[0].message.content\n",
    "    # Get the seed, token usage, and the text\n",
    "    print(tokens)\n",
    "    print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26becbe3-88ec-46d1-b93f-c09aa8a96638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427\n",
      "Here's a little story that can fill you in on what I know.\n",
      "\n",
      "A recent study says that the best way to stay healthy is to exercise regularly and eat a balanced diet. However, not everyone has the time or motivation to do so. \n",
      "\n",
      "Ones who are looking for a quick and easy way to improve their health might consider using wearable devices such as fitness trackers or smartwatches. These devices can track your activity levels, heart rate, and even monitor your sleep patterns. \n",
      "\n",
      "But be careful when choosing which devices to use. Some cheaper options may not be as accurate or reliable as others. It's important to do your research and read reviews before making a purchase. \n",
      "\n",
      "Anyone have any advice on which devices are the best for tracking fitness and health? \n",
      "\n",
      "Why I posted it in technology - I think wearable devices are the future of health and fitness. Not sure. But with all the advancements in technology, this might be the place to uncover something new and exciting. \n",
      "\n",
      "Thanks.\n",
      "['says', 'ones', 'devices']\n"
     ]
    }
   ],
   "source": [
    "# Model below is from r/conspiracy\n",
    "# 7th top post of the day at 2023-06-03-0800\n",
    "# https://www.reddit.com/r/conspiracy/comments/13zamrr/\\\n",
    "# foreign_powers_are_destabilizing_the_us/\n",
    "keys = random.sample(keywords, 3)\n",
    "model = random.sample(substantive,1)\n",
    "\n",
    "query = f\"\"\"\n",
    "Create a text in the style of the text provided below\n",
    "but change the topics to: {keys}.\n",
    "\n",
    "{model}\n",
    "\"\"\"\n",
    "\n",
    "chatgptquery(query)\n",
    "print(keys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
