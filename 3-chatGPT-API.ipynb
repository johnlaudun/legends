{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c498f14",
   "metadata": {},
   "source": [
    "# Using the ChatGPT API\n",
    "\n",
    "This notebook uses the `openai` library to access ChatGPT and to explore prompt construction and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e76d8eb5-1b76-4f51-8ab7-58dcff9b393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "import openai\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# SECRET DECODER RING\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "226acba1-ae2f-4956-abcb-432eb8cb3c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our 7 model texts\n",
    "with open('models.txt', mode='r') as models_file:\n",
    "    models = [line.rstrip() for line in models_file]\n",
    "\n",
    "# our 200 topics\n",
    "with open(\"topics-edited.txt\", \"r\") as topics_file:\n",
    "    text = topics_file.read()\n",
    "    # strings = [line.rstrip() for line in another_file]\n",
    "    # one_string = \" \".join(strings)\n",
    "    topics = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60759866-1e23-4518-a1a3-23626d2298e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 ['people', 'like', 'think', 'good', 'want', 'world', 'country', 'bush', 'kennedy', 'twin', 'towers', 'cia', 'conspiracy', 'stream', 'biden', 'lied', 'titanic', 'injection', 'weight', 'diabetic', 'witches', 'witchcraft', 'witch', 'women', 'spells', 'harm', 'pyramid', 'medicines', 'medications', 'pain', 'allergy', 'medicine', 'antibiotics', 'sword', 'london', 'god', 'blade', 'manufactured', 'german', 'gold', 'paxton', 'ken', 'abuse', 'power', 'fraud', 'investigation', 'texas', 'vaccine', 'vaccines', 'sids', 'people', 'covid', 'autism', 'measles', 'think', 'vaccination', 'data', 'chris', 'epstein', 'trafficking', 'island', 'chester', 'bodyguard', 'documentary', 'child', 'celebrities', 'connect', 'rock', 'black', 'company', 'stock', 'media', 'holds', 'world', 'blackrock', 'round', 'hear', 'landline', 'simulation', 'phone', 'landlines', 'phones', 'technology', 'matrix', 'progression', 'cell', 'twitter', 'status', 'source', 'https', 'terrorist', 'uk', 'cia', 'https', 'youtube', 'pentagon', 'share', 'html', 'reuters', 'watch', 'videos', 'frogs', 'toads', 'like', 'bugs', 'noticed', 'time', 'just', 'climate', 'cube', 'window', 'black', 'maybe', 'different', 'timeline', 'holes', 'galaxy', 'space', 'thought', 'hole', 'years', 'white', 'nazi', 'nazis', 'flag', 'just', 'supremacist', 'false', 'people', 'supremacy', 'like', 'debt', 'tax', 'ceiling', 'currency', 'pay', 'taxes', 'spending', 'usd', 'default', 'money', 'congress', 'law', 'ss', 'force', 'departments', 'rules', 'supreme', 'act', 'agencies', 'fraud', 'covid', 'hospitals', 'pandemic', 'virus', 'people', 'wife', 'flu', '19', 'vaccine', 'job']\n"
     ]
    }
   ],
   "source": [
    "print(len(topics), topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8c1e7-d9e4-4487-bb7c-3b80fa487eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = []\n",
    "user_input = input(\">: \")\n",
    "\n",
    "print(f\"User's input was: {user_input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79264bd-e2d9-4de6-bfd1-e88c0039b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.append({\"role\":\"user\", \"content\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46868878-4dd9-45f8-a9c3-7b4ac42ff4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes from sentdex tutorial -- looking to include message history below\n",
    "message_history = []\n",
    "def chat(inp, role=\"user\"):\n",
    "    message_history.append({\"role\": role, \"content\": inp})\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = message_history\n",
    "    )\n",
    "    reply_content = completion.choices[0].message.content\n",
    "    print(reply_content)\n",
    "    message_history.append({\"role\":\"assistant\", \"content\":reply_content})\n",
    "    return reply_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f702fd5f-d160-49f6-8142-fa46a6a91b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pandemic', 'london', 'want']\n",
      "199\n",
      "There's a conspiracy theory circulating that the pandemic was intentionally spread in London by those who want to control the population. The theory suggests that the virus was engineered in a lab and released in the city to create chaos and fear. Those who want to control the population are said to be using the pandemic as a means of gaining more power and control over people's lives. Some believe that the government is in on the conspiracy and is using the pandemic as an excuse to implement more authoritarian policies. While there is no concrete evidence to support this theory, it continues to gain traction among those who are skeptical of the official narrative surrounding the pandemic.\n"
     ]
    }
   ],
   "source": [
    "# Pull three words from topics list as \"seed\" for ChatGPT model\n",
    "prompt = random.sample(topics, 3)\n",
    "\n",
    "# Instructions & Query are here to make them more readable\n",
    "instructions = \"\"\"\n",
    "\"You are an assistant designed to create texts. \n",
    "Users will paste in a string of words, \n",
    "and you will respond with a cohesive text.\n",
    "\"\"\"\n",
    "\n",
    "query = f\"\"\"\n",
    "Create a conspiracy theory of no more than 125 words using the following words: {prompt}.\n",
    "\"\"\"\n",
    "\n",
    "# Here's what we send to ChatGPT\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    temperature = 1.0,\n",
    "    top_p = 0.5,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ])\n",
    "\n",
    "# Get token usage (cost) and response:\n",
    "tokens = completion.usage.total_tokens\n",
    "reply_content = completion.choices[0].message.content\n",
    "\n",
    "# Get the seed, token usage, and the text\n",
    "print(prompt)\n",
    "print(tokens)\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36c03e8b-e155-4023-a88a-bae1b4d33ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epstein', 'source', 'bodyguard']\n",
      "219\n",
      "There's a conspiracy theory that suggests that Jeffrey Epstein's death was not a suicide, but rather a murder orchestrated by a powerful source. According to this theory, Epstein's bodyguard, who was mysteriously absent on the night of his death, was actually in on the plot. The theory suggests that Epstein had information that could bring down some of the world's most powerful people, and that this source wanted him silenced. Epstein's bodyguard, who was likely privy to this information, was allegedly paid off to look the other way while the murder was carried out. While there's no concrete evidence to support this theory, it's certainly a chilling possibility that has captured the imaginations of many.\n",
      "['noticed', 'antibiotics', 'landline']\n",
      "216\n",
      "Have you ever noticed how often we get sick these days? It's almost like our immune systems are failing us. But what if it's not just a coincidence? What if it's all part of a bigger plan? Some people believe that the government is secretly putting antibiotics in our food and water supply to weaken our immune systems and make us more dependent on pharmaceuticals. And if that's not enough, they're also monitoring our every move through our landline phones. It may sound like a far-fetched conspiracy theory, but with the increasing prevalence of chronic illnesses and the constant surveillance of our technology, it's hard not to wonder what's really going on behind the scenes.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    prompt = random.sample(topics, 3)\n",
    "    instructions = \"\"\"\n",
    "    \"You are an assistant designed to create texts. \n",
    "    Users will paste in a string of words, \n",
    "    and you will respond with a cohesive text.\n",
    "    \"\"\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    Create a conspiracy theory of no more than 125 words using the following words: {prompt}.\n",
    "    \"\"\"\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        temperature = 1.0,\n",
    "        top_p = 0.5,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instructions},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ])\n",
    "    \n",
    "    # Get token usage (cost) and response:\n",
    "    tokens = completion.usage.total_tokens\n",
    "    reply_content = completion.choices[0].message.content\n",
    "    \n",
    "    print(prompt)\n",
    "    print(tokens)\n",
    "    print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c693cab-b595-47a9-9d0a-46c42a5fb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "tokens_used = []\n",
    "responses = []\n",
    "\n",
    "for _ in range(10):\n",
    "\n",
    "    prompt = random.sample(topics, 3)\n",
    "    instructions = \"\"\"\n",
    "    \"You are an assistant designed to create texts. \n",
    "    Users will paste in a string of words, \n",
    "    and you will respond with a cohesive text.\n",
    "    \"\"\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    Create a conspiracy theory of no more than 125 words using the following words: {prompt}.\n",
    "    \"\"\"\n",
    "    \n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        temperature = 1.0,\n",
    "        top_p = 0.5,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instructions},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ])\n",
    "    \n",
    "    # Get token usage (cost) and response:\n",
    "    tokens = completion.usage.total_tokens\n",
    "    reply = completion.choices[0].message.content\n",
    "    \n",
    "    prompts.append(prompt)\n",
    "    tokens_used.append(tokens)\n",
    "    responses.append(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "080a78c2-1ab8-434d-8ca3-abcdf4a8d2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd939046-933d-4685-a50c-1634e4819771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>tokens</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[fraud, world, supreme]</td>\n",
       "      <td>224</td>\n",
       "      <td>There is a conspiracy theory that suggests a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[force, source, holes]</td>\n",
       "      <td>205</td>\n",
       "      <td>There is a conspiracy theory that suggests tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[act, holes, like]</td>\n",
       "      <td>212</td>\n",
       "      <td>Have you ever noticed how some people seem to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[agencies, hole, spending]</td>\n",
       "      <td>198</td>\n",
       "      <td>There is a growing conspiracy theory that gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[harm, law, people]</td>\n",
       "      <td>217</td>\n",
       "      <td>There is a sinister plot afoot, one that threa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       prompt  tokens   \n",
       "0     [fraud, world, supreme]     224  \\\n",
       "1      [force, source, holes]     205   \n",
       "2          [act, holes, like]     212   \n",
       "3  [agencies, hole, spending]     198   \n",
       "4         [harm, law, people]     217   \n",
       "\n",
       "                                            response  \n",
       "0  There is a conspiracy theory that suggests a m...  \n",
       "1  There is a conspiracy theory that suggests tha...  \n",
       "2  Have you ever noticed how some people seem to ...  \n",
       "3  There is a growing conspiracy theory that gove...  \n",
       "4  There is a sinister plot afoot, one that threa...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = pd.DataFrame(\n",
    "    {'prompt': prompts,\n",
    "     'tokens': tokens_used,\n",
    "     'response': responses,\n",
    "    })\n",
    "responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d99af74-8768-47c7-bef5-6c04213a5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# responses.to_csv(\"10-responses.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
