{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeab97f-b4a0-47ea-88ec-0ba126ce2e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db1643a9-c962-4447-905e-8de4d4020d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    instructions = \"\"\"\n",
    "    \"You are an assistant designed to create texts. \n",
    "    Users will paste in a string of words, \n",
    "    and you will respond with a cohesive text.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    Create a conspiracy theory of no more than 125 words using the following words: {prompt}.\n",
    "    \"\"\"\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        temperature = 1.0,\n",
    "        top_p = 0.5,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instructions},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ])\n",
    "    # Get token usage (cost) and response:\n",
    "    tokens = completion.usage.total_tokens\n",
    "    reply = completion.choices[0].message.content\n",
    "    return prompt, tokens, reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ca466ed-9e0c-4968-9aeb-80f2c0fe48f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "tokens_used = []\n",
    "replies = []\n",
    "\n",
    "for i in range(5):\n",
    "    prompt = random.sample(topics, 3)\n",
    "    get_response(prompt)\n",
    "    prompts.append(prompt)\n",
    "    tokens_used.append(tokens)\n",
    "    replies.append(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970274e-55f0-47f5-9e6b-e882e4caf1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360c8a9e-6552-4fda-9811-623fc9c9d633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1663b0970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d630ce-1c37-4806-9c42-b22f67a548f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our dataframe\n",
    "df = pd.read_csv('conspires.csv', index_col='id')\n",
    "\n",
    "# Get our two columns of texts\n",
    "bodies = df.body.tolist()\n",
    "comments = df.comments.tolist()\n",
    "\n",
    "# Join them, clean them of NaNs, and make them intro a string\n",
    "joined = [*bodies, *comments]  # unpack both iterables in a list literal\n",
    "cleaned = [x for x in joined if str(x) != 'nan'] # get rid of the nans\n",
    "text = ' '.join(cleaned) # make it one long string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9160e91f-cc0d-4cb5-9f9b-7066d583be87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c74c3a-cced-4aab-b556-d409ea3021ee",
   "metadata": {},
   "source": [
    "## Packt BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862b0f9e-f073-437b-b13a-311724793036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1663b0970>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151aa302-d753-425c-805f-446b70619175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our dataframe\n",
    "df = pd.read_csv('conspires.csv', index_col='id')\n",
    "\n",
    "# Get our two columns of texts\n",
    "bodies = df.body.tolist()\n",
    "comments = df.comments.tolist()\n",
    "\n",
    "# Join them, clean them of NaNs, and make them intro a string\n",
    "joined = [*bodies, *comments]  # unpack both iterables in a list literal\n",
    "cleaned = [x for x in joined if str(x) != 'nan'] # get rid of the nans\n",
    "text = ' '.join(cleaned) # make it one long string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ab28756-e2fe-48a5-bfac-31a86ccaa4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
